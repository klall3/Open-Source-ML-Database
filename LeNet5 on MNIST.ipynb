{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet 5 (A close approximation) on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The Keras imports\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the basic constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes      = 10        # There are 10 digits\n",
    "mini_batch   = 128       # The mini-batch size\n",
    "epochs       = 20       # number of epochs to run (be careful!)\n",
    "activation   = 'relu'    # pick the activation (relu, tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and test data splits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#First, unflatten the images to be 28x28 pixels which they originally are\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "\n",
    "# Add the \\\"channel\\\" dimension. For images it is usually the rgb. Here it is grayscale, so we have only 1-channel added\n",
    "x_train= x_train[:, :, :, np.newaxis]\n",
    "x_test = x_test[:,:,:, np.newaxis]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Let us scale the values to be between [0,1]. Since the original pixel values are from 0-255\\n\", we scale it down\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# The one-hot encoding of the response (0-9 digits). In other words, \\\"4\\\" looks like [0,0,0,0,1,0,0,0,0,0]\n",
    "y_train_hot = to_categorical(y_train, 10)\n",
    "y_test_hot  = to_categorical(y_test, 10)\n",
    "\n",
    "# Pad the 28x28 images with 2-pixel border all around, get 32x32. The original paper uses 32x32 size images, so if we have to pass the MNIST images, we need to pad it\n",
    "\n",
    "# The padding is as follows:\n",
    "# no padding of the rows, so the first (0,0)\n",
    "# pad the width in the left and right by 2 pixels, so the (2,2)\n",
    "# pad the height in the top and bottom by 2 pixels, so the next (2,2)\n",
    "# no padding of the channels -- we leave it as 1, so the final (0,0)\n",
    "\n",
    "x_train = np.pad(x_train, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "x_test = np.pad(x_test, ((0,0), (2,2), (2,2), (0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the LeNet5 CNN Architecture (Approximately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LeNet5Model ():\n",
    "    #An approximation to the original LeNet5 model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Now, lets build the first Convulational layer with the three pieces: Conv-filter layer, ReLu activation layer, followed by AveragePooling layer\n",
    "    # Note that today we would instead use MaxPooling, but in those days AveragePooling was customary,\n",
    "    # Originally, tanh was used as the activation function, though today, it would make sense to use ReLu (much faster!)\n",
    "    \n",
    "    conv1 = Conv2D(filters=6,             # Look for six features\n",
    "                   kernel_size=5,         # Use a 5x5 filter (kernel)\n",
    "                   strides=1,             # the filter-stride while scanning\n",
    "                   activation=activation, # activation function\n",
    "                   input_shape=(32,32,1))  # Gray-scale image of 32x32 pixels\n",
    "    avePool1 = AveragePooling2D(pool_size=2, strides=2)\n",
    "    \n",
    "    conv2 = Conv2D(filters=16,            # Look for sixteen features\n",
    "                   kernel_size=5,         # Use a 5x5 filter (kernel)\n",
    "                   strides=1,             # the filter-stride while scanning\n",
    "                   activation=activation) # activation function\n",
    "    avePool2 = AveragePooling2D(pool_size=2, strides=2)\n",
    "\n",
    "    flatten = Flatten()\n",
    "    fcLayer3     = Dense(units=120, activation=activation)\n",
    "    fcLayer4     = Dense(units=84,  activation=activation)\n",
    "\n",
    "    # Finally, the output layer using softmax to recognize the 10 digits\n",
    "    outputLayer = Dense (10, activation='softmax')\n",
    "\n",
    "    model.add(conv1)       # first convulation\n",
    "    model.add(avePool1)    # pooling\n",
    "    model.add(conv2)       # second convulation\n",
    "    model.add(avePool2)    # pooling\n",
    "    model.add(flatten)     # flatten in a single vector\n",
    "    model.add(fcLayer3)    # fully connected layer of 120 neurons\n",
    "    model.add(fcLayer4)    # fully connected layer of 84 neurons\n",
    "    model.add(outputLayer) # output\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 1.9886 - acc: 0.3429\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.4688 - acc: 0.8635\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.3247 - acc: 0.9023\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.2707 - acc: 0.9186\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.2331 - acc: 0.9303\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.2079 - acc: 0.9375\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.1843 - acc: 0.9452\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.1678 - acc: 0.9489\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1539 - acc: 0.9533\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.1407 - acc: 0.9574\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.1313 - acc: 0.9603\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.1224 - acc: 0.96271s - los\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.1145 - acc: 0.9657\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.1096 - acc: 0.9670\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1024 - acc: 0.9694\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0971 - acc: 0.9708\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0935 - acc: 0.9716\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.0886 - acc: 0.9733\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.0854 - acc: 0.9736\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.0816 - acc: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb489c55f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_LeNet5Model()\n",
    "\n",
    "model.compile(optimizer=SGD(), # use the SGD (now,Adam would work much faster)\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics= ['accuracy'])\n",
    "                   \n",
    "# Train the model on the training images\n",
    "model.fit(x_train,                      # the predictors\n",
    "          y_train_hot,                  # the response\n",
    "          batch_size=mini_batch,        # mini-batch size\n",
    "          epochs = epochs,              # number of epochs to run\n",
    "          verbose = 1)                  # print out the executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 96us/step\n",
      "The Accuracy is: 0.9728, the residual loss is: 0.08115393745303154\n"
     ]
    }
   ],
   "source": [
    "# Now evaluate the model for accuracy\n",
    "(loss, accuracy) = model.evaluate(x_test, \n",
    "                                  y_test_hot,\n",
    "                                  batch_size = mini_batch,\n",
    "                                  verbose = 1)\n",
    "print(f'The Accuracy is: {accuracy}, the residual loss is: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
